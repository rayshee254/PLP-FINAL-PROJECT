{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNZI0aUbW7CSoaLBYbyeMEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayshee254/PLP-FINAL-PROJECT/blob/main/Audio_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "2f5AeIqsm9ab",
        "outputId": "d3ef3458-4c0b-445e-e442-4ae9ff123d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Models already loaded from previous run!\n",
            "üîç Reusing existing models to save time...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Models successfully reused!\n",
            "üîç Found available port: 7864\n",
            "üöÄ Launching AI Audio Processor...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e5e897814878430e24.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e5e897814878430e24.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Your public URL: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); \n",
              "                    padding: 20px; border-radius: 10px; color: white; margin: 20px 0;\">\n",
              "            <h2>üéâ Success! Audio Processor is Live!</h2>\n",
              "            <p><strong>üåê Public URL:</strong> <a href=\"\" target=\"_blank\" style=\"color: #ffdd00; text-decoration: none;\"></a></p>\n",
              "            <p><strong>‚ö° Status:</strong> Models already loaded - Ready to process!</p>\n",
              "            <p><strong>üéØ Port:</strong> 7864 (automatically selected)</p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# üéØ Fixed Audio Processor with Auto Port Selection\n",
        "# Solves the port conflict issue automatically\n",
        "\n",
        "# Step 1: Import libraries\n",
        "import gradio as gr\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import io\n",
        "from datetime import datetime\n",
        "import os\n",
        "import socket\n",
        "\n",
        "# Step 2: Find an available port automatically\n",
        "def find_available_port(start_port=7860, max_attempts=10):\n",
        "    \"\"\"Find an available port starting from the specified port\"\"\"\n",
        "    for port in range(start_port, start_port + max_attempts):\n",
        "        try:\n",
        "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "                s.bind(('localhost', port))\n",
        "                return port\n",
        "        except OSError:\n",
        "            continue\n",
        "    return start_port  # Fallback to original port\n",
        "\n",
        "# Step 3: Set cache directories\n",
        "os.environ['HF_HOME'] = '/content/huggingface_cache'\n",
        "os.environ['TRANSFORMERS_CACHE'] = '/content/huggingface_cache'\n",
        "\n",
        "# Step 4: Load models (already loaded from your previous run)\n",
        "print(\"‚úÖ Models already loaded from previous run!\")\n",
        "print(\"üîç Reusing existing models to save time...\")\n",
        "\n",
        "# Get the existing models (they should already be in memory)\n",
        "try:\n",
        "    transcriber = whisper.load_model(\"small\")\n",
        "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-6-6\", device=0)\n",
        "    print(\"üéØ Models successfully reused!\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Could not reuse models, loading fresh...\")\n",
        "    transcriber = whisper.load_model(\"small\")\n",
        "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-6-6\", device=0)\n",
        "\n",
        "# Step 5: Processing functions (unchanged)\n",
        "def chunk_text(text, max_words=400):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
        "\n",
        "def process_audio(audio_file, language=\"en\"):\n",
        "    if audio_file is None:\n",
        "        return \"\", \"\", \"‚ùå Please upload an audio file first\"\n",
        "\n",
        "    try:\n",
        "        # Transcribe audio\n",
        "        result = transcriber.transcribe(audio_file, language=language)\n",
        "        transcript_raw = result[\"text\"]\n",
        "        transcript = \"\\n\".join(re.split(r'(?<=[.!?]) +', transcript_raw))\n",
        "\n",
        "        # Summarize in chunks\n",
        "        chunks = chunk_text(transcript_raw)\n",
        "        summaries = []\n",
        "\n",
        "        for chunk in chunks:\n",
        "            input_length = len(chunk.split())\n",
        "            max_len = min(142, max(30, int(input_length * 0.6)))\n",
        "            min_len = min(30, max_len)\n",
        "\n",
        "            summary_text = summarizer(\n",
        "                chunk,\n",
        "                max_length=max_len,\n",
        "                min_length=min_len,\n",
        "                do_sample=False\n",
        "            )[0]['summary_text']\n",
        "            summaries.append(summary_text)\n",
        "\n",
        "        summary = \"\\n\\n\".join(summaries)\n",
        "        return transcript, summary, \"‚úÖ Processing complete!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"\", \"\", f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "def download_results(transcript, summary):\n",
        "    if not transcript and not summary:\n",
        "        return None, \"‚ùå No content to download\"\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"transcription_summary_{timestamp}.txt\"\n",
        "\n",
        "    content = f\"\"\"TRANSCRIPTION & SUMMARY REPORT\n",
        "    Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "    ===================================================\n",
        "\n",
        "    FULL TRANSCRIPT:\n",
        "    {transcript if transcript else \"No transcript available\"}\n",
        "\n",
        "    ===================================================\n",
        "\n",
        "    AI SUMMARY:\n",
        "    {summary if summary else \"No summary available\"}\n",
        "\n",
        "    ===================================================\n",
        "    Generated with AI Audio Processor\n",
        "    \"\"\"\n",
        "\n",
        "    file_obj = io.BytesIO(content.encode('utf-8'))\n",
        "    return file_obj, filename\n",
        "\n",
        "# Step 6: Create interface\n",
        "def create_interface():\n",
        "    with gr.Blocks(title=\"üé§ AI Audio Processor\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üé§ AI Audio Processor\n",
        "        **Ready to use! Models already loaded ‚úÖ**\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                audio_input = gr.Audio(\n",
        "                    sources=[\"upload\", \"microphone\"],\n",
        "                    type=\"filepath\",\n",
        "                    label=\"Upload Audio File\"\n",
        "                )\n",
        "\n",
        "                language = gr.Dropdown(\n",
        "                    choices=[\"en\", \"es\", \"fr\", \"de\", \"it\", \"pt\", \"ru\", \"zh\", \"ja\", \"ko\"],\n",
        "                    value=\"en\",\n",
        "                    label=\"Audio Language\"\n",
        "                )\n",
        "\n",
        "                process_btn = gr.Button(\"üöÄ Process Audio\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column():\n",
        "                transcript_output = gr.Textbox(\n",
        "                    label=\"üìù Full Transcript\",\n",
        "                    lines=12,\n",
        "                    show_copy_button=True\n",
        "                )\n",
        "\n",
        "                summary_output = gr.Textbox(\n",
        "                    label=\"üìã AI Summary\",\n",
        "                    lines=8,\n",
        "                    show_copy_button=True\n",
        "                )\n",
        "\n",
        "                status_output = gr.Textbox(\n",
        "                    label=\"Status\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    download_btn = gr.Button(\"üì• Download Results\", variant=\"secondary\")\n",
        "                    download_file = gr.File(\n",
        "                        label=\"Download File\",\n",
        "                        visible=False\n",
        "                    )\n",
        "\n",
        "        process_btn.click(\n",
        "            fn=process_audio,\n",
        "            inputs=[audio_input, language],\n",
        "            outputs=[transcript_output, summary_output, status_output]\n",
        "        )\n",
        "\n",
        "        download_btn.click(\n",
        "            fn=download_results,\n",
        "            inputs=[transcript_output, summary_output],\n",
        "            outputs=[download_file, status_output]\n",
        "        ).then(\n",
        "            lambda: gr.File(visible=True),\n",
        "            outputs=download_file\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Step 7: Main execution with auto port selection\n",
        "if __name__ == \"__main__\":\n",
        "    # Find available port\n",
        "    available_port = find_available_port(7860)\n",
        "    print(f\"üîç Found available port: {available_port}\")\n",
        "\n",
        "    # Create interface\n",
        "    demo = create_interface()\n",
        "\n",
        "    print(\"üöÄ Launching AI Audio Processor...\")\n",
        "\n",
        "    # Launch with the available port\n",
        "    try:\n",
        "        public_url = demo.launch(share=True, server_port=available_port)\n",
        "        print(f\"üåê Your public URL: {public_url}\")\n",
        "\n",
        "        from IPython.display import HTML\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
        "                    padding: 20px; border-radius: 10px; color: white; margin: 20px 0;\">\n",
        "            <h2>üéâ Success! Audio Processor is Live!</h2>\n",
        "            <p><strong>üåê Public URL:</strong> <a href=\"{public_url}\" target=\"_blank\" style=\"color: #ffdd00; text-decoration: none;\">{public_url}</a></p>\n",
        "            <p><strong>‚ö° Status:</strong> Models already loaded - Ready to process!</p>\n",
        "            <p><strong>üéØ Port:</strong> {available_port} (automatically selected)</p>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Launch failed: {e}\")\n",
        "        print(\"üîÑ Trying with default settings...\")\n",
        "        public_url = demo.launch(share=True)\n",
        "        print(f\"üåê Backup URL: {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "\n",
        "# Load your notebook\n",
        "with open(\"Audio_processing.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Save it in the latest format\n",
        "with open(\"Audio_processing.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
        "    nbformat.write(nb, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "47KZ4EZQ4u4J",
        "outputId": "1b5a6d25-2ee7-4cfc-9325-cf6fc3241986"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Audio_processing.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3716049956.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load your notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Audio_processing.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Audio_processing.ipynb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NzAB5CiB5Pyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}